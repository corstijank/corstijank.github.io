<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dotnet on Statics Must Die!</title>
    <link>http://staticsmustdie.net/tags/dotnet/index.xml</link>
    <description>Recent content in Dotnet on Statics Must Die!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</copyright>
    <atom:link href="http://staticsmustdie.net/tags/dotnet/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Crossing Styx - My journey into the (under)world of .NET - Part III</title>
      <link>http://staticsmustdie.net/post/dotnetcore-adventures-iii/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>http://staticsmustdie.net/post/dotnetcore-adventures-iii/</guid>
      <description>

&lt;p&gt;In the third part of the series, our adventure is slowly but surely heading to its climax. All &amp;lsquo;characters&amp;rsquo; have been introduced. There&amp;rsquo;s &lt;strong&gt;DotNet Core&lt;/strong&gt;, the new, misunderstood (or at least by me?) kid with a bunch of talent. &lt;strong&gt;Docker&lt;/strong&gt;, the awesome supporting character that actually deserves his own movie. Surely there&amp;rsquo;ll be a spin-off! There&amp;rsquo;s the antagonist, &lt;strong&gt;Jenkins&lt;/strong&gt;, who might end up working along with our main character more then either had hoped for. Then, there&amp;rsquo;s the mid movie surprise character, &lt;strong&gt;Microsoft SQL server&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;And then there&amp;rsquo;s me, the engineer coming from a Java EE background trying to piece it all together.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s just hope this story doesn&amp;rsquo;t end up on rottentomatoes&amp;hellip;&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://staticsmustdie.net/img/dotnet-jenkins-tests-succesful.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;You can tell it&amp;#39;s not actually doing much by the green color.&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;challenge-accepted&#34;&gt;Challenge accepted&lt;/h2&gt;

&lt;p&gt;In the previous posts (&lt;a href=&#34;http://staticsmustdie.net/post/dotnetcore-adventures-i/&#34;&gt;part I&lt;/a&gt;, &lt;a href=&#34;http://staticsmustdie.net/post/dotnetcore-adventures-ii/&#34;&gt;part II&lt;/a&gt;) I have been building a dotnet core application. Not wanting to start from scratch, I adopted a simple TodoAPI example from the (still excellent) ASP.NET core tutorials. I wound up with a REST api to &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;POST&lt;/code&gt; some todo items. This was a good starting point, but for me, I can&amp;rsquo;t seriously say that I now know dotnet, or even have written something remotely useful in it. The biggest thing missing for me was something that most &amp;lsquo;tutorial&amp;rsquo; applications lack, and which every real life application has;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Run time dependencies&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I mean, sure it has dependencies on ASP.NET core. But when it comes to deploying and running, it&amp;rsquo;s a simple application. Very few real services are like that. Services, ironically, often require other services to run. A backend needs databases or messages, a frontend needs a backend, and so on. Even if you go all fancy microservices in your architecture, chances are you&amp;rsquo;re still managing processes for databases or message queuing. I&amp;rsquo;m just going to assume you&amp;rsquo;re not writing your services from http to flat files all yourself. Anyway, inter-process dependencies like that are often the challenging factor in delivering software. So, let&amp;rsquo;s not shy away from a challenge.&lt;/p&gt;

&lt;p&gt;For a todo rest api, the most logical thing would be to add persistence. Right now, if we restart our container, we lose all todo items previously registered. Not the most user-friendly experience. I&amp;rsquo;m out of metaphor&amp;rsquo;s to explain this, but when I think persistence and Microsoft technology, I think SQL server. For a long while, it would not have been an option, since it used to run exclusively on Windows. But, a few months back, a new SQL server version was released, which ran on Linux. Not even that, it ran in a Docker container too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://staticsmustdie.net/img/sqlserver-linux.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Excellent&amp;hellip;&amp;hellip;&lt;em&gt;cue evil laughter&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;core-makes-everything-cooler&#34;&gt;Core makes everything cooler&lt;/h2&gt;

&lt;p&gt;So, persistence for a dotnet application. What to framework to use. On the java side of things, we have basically two &amp;lsquo;flavors&amp;rsquo; of frameworks. A kind of Object Relation Mapping solution; think Hibernate, if you will. If you&amp;rsquo;re more into writing pure SQL, and mapping that to objects, you can use a query mapping framework. Think something like myBatis. There are probably a bunch more in both categories, but I&amp;rsquo;m not writing about Java now.&lt;/p&gt;

&lt;p&gt;Looking at the (once again, excellent) dotnet and ASP.NET core tutorials, one quickly stumbles upon something called EntityFrameworkCore. Now, I know I have criticized Microsofts naming strategy for frameworks before. Usually it&amp;rsquo;s just boring, summarizing what the framework does. Blergh. Same goes here, except&amp;hellip;for some reason, I like EntityFrameworkCore. Probably because &amp;lsquo;core&amp;rsquo; bit makes it sound more&amp;hellip;well..hardCore? If it had just been EntityFramework (which I believe it&amp;rsquo;s still called in the &amp;lsquo;vanilla&amp;rsquo; .NET variant), I&amp;rsquo;d not be a fan.&lt;/p&gt;

&lt;p&gt;Anyway, as you can guess by now, there&amp;rsquo;s a bunch of tutorials on EntityFrameworkCore. But, none of those actually &amp;lsquo;integrate&amp;rsquo; into the Todo tutorial.&lt;/p&gt;

&lt;p&gt;But, no worries; I can still program some myself, believe it or not.&lt;/p&gt;

&lt;p&gt;So, first off, I can just use my plain old TodoItem class as an entity;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;public class TodoItem
{
    public string TodoItemID { get; set; }
    public string Name { get; set; }
    public bool IsComplete { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The idea, as far as I can tell, is that there is a user-created &amp;lsquo;context&amp;rsquo; class, that extends &lt;code&gt;DbContext&lt;/code&gt;. So, I made a TodoContext, with the idea it&amp;rsquo;ll manage all entities for my todo api.  In the TodoContext class, I register the entity TodoItem and state which table it is to be saved in. I give the TodoContext class a public property &lt;code&gt;DbSet&amp;lt;TodoItem&amp;gt; TodoItems&lt;/code&gt; and all should be good to go for my business methods;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;public class TodoContext : DbContext
{
    public TodoContext(DbContextOptions&amp;lt;TodoContext&amp;gt; options) : base(options)
    {
    }
    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.Entity&amp;lt;TodoItem&amp;gt;().ToTable(&amp;quot;TodoItem&amp;quot;);
    }
    public DbSet&amp;lt;TodoItem&amp;gt; TodoItems { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And yes,  behold, my &amp;lsquo;business&amp;rsquo; logic can now use the TodoContext to do some persistence stuff:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;_dbContext.Update(item);
_dbContext.SaveChanges();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yes, there needs to be a call to &lt;code&gt;.SaveChanges()&lt;/code&gt; - Which, for me as a java programmer coming from a Java EE world, is a bit silly. As in, I honestly forgot to do it in my first go. Why isn&amp;rsquo;t there a container to manage this transactional stuff? But then, when I&amp;rsquo;m completely honest with myself, in that question lies the answer already. There is no container, it&amp;rsquo;s not Java EE, and doing something like this is not all that weird even in other languages.&lt;/p&gt;

&lt;p&gt;I know, I know,  but it&amp;rsquo;s so much more easy to hate then it is to tolerate, right?&lt;/p&gt;

&lt;h2 id=&#34;holding-the-line&#34;&gt;Holding the line&lt;/h2&gt;

&lt;p&gt;Of course, doing all this work still did not connect it to any SQL server instance, make a database or tables, or actually even run at all. There&amp;rsquo;s still initialization and setup to do!&lt;/p&gt;

&lt;p&gt;So, in our StartUp class, where all injectable services are configured, we add a simple line:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt; services.AddDbContext&amp;lt;TodoContext&amp;gt;(options =&amp;gt;
    options.UseSqlServer(Configuration.GetConnectionString(&amp;quot;DefaultConnection&amp;quot;)));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And as you can imagine, we add a connectionstring &amp;lsquo;DefaultConnection to the file called &lt;code&gt;AppSettings.json&lt;/code&gt;;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt; &amp;quot;DefaultConnection&amp;quot;: &amp;quot;Data Source=localhost,1433;
 	Initial Catalog=TodoDev;Integrated Security=False;
 	User ID=sa;Password=xihdG!8uNCavA!Rw&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m sure it&amp;rsquo;s a terrible connection string. But it works. Yes, you know the password to my sql server instance&amp;hellip;. &lt;em&gt;Or do you&lt;/em&gt;?&lt;/p&gt;

&lt;p&gt;That all seems to work fine, assuming the database exists. And here we get into a pickle. Because, I do not want to depend on that. I want EntityFrameworkCore to create it for me. Not just the tables, but the whole database. Luckily, the tutorials help me out there, and tell me how to set up an initializer class, with even some code to populate some data into it. Nice.&lt;/p&gt;

&lt;p&gt;Just create a &lt;code&gt;DbInitializer&lt;/code&gt; class, and make sure to call the method in the startup class&amp;rsquo; &lt;code&gt;configure&lt;/code&gt; method. Let&amp;rsquo;s copy and past&amp;hellip;..wait a minute&amp;hellip;is that a &lt;code&gt;static&lt;/code&gt; method in that &lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/data/ef-mvc/intro#add-code-to-initialize-the-database-with-test-data&#34;&gt;initializer example&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://staticsmustdie.net/img/stayalert.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now, there are lines to be held. The url you are currently browsing is &lt;code&gt;staticsmustdie.net&lt;/code&gt; - I cannot go and claim we need a static method for something as silly as database initialization. It&amp;rsquo;s not necessary, it&amp;rsquo;s lazy, and it must be stopped. So, as that &lt;em&gt;Rage Against the Machine&lt;/em&gt; song goes&amp;hellip;.yeah&amp;hellip; I won&amp;rsquo;t do what you tell me.&lt;/p&gt;

&lt;p&gt;So what do I do? Simple enough, drop the static, inject a new instance. Create testable code. Boom.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;public class DbInitializer
{
    public void Initialize(TodoContext context)
    {
        context.Database.EnsureCreated();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;public void ConfigureServices(...)
{
	// other stuff going on as well
    services.AddSingleton&amp;lt;DbInitializer,DbInitializer&amp;gt;();  
}
public void Configure(...)
{
    // other stuff going on as well
    dbInitializer.Initialize(dbContext);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This leaves me with a nice &lt;code&gt;DbInitializer&lt;/code&gt; class, where I can add some dummy data if I want as well. But honestly, if that were to be all the code in a &lt;code&gt;DbInitializer&lt;/code&gt; in a &amp;lsquo;real&amp;rsquo; project, I would probably just inline the &lt;code&gt;context.Database.ensureCreated()&lt;/code&gt; call to the StartUp&amp;rsquo;s &lt;code&gt;Configure&lt;/code&gt; method.&lt;/p&gt;

&lt;p&gt;But I wanted to make a statement. &lt;strong&gt;Against statics&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;composing-like-mozart-but-less-classical&#34;&gt;Composing. Like Mozart. But less classical.&lt;/h2&gt;

&lt;p&gt;So, our service is coming along nicely. Using a local SQL Server (thanks to Docker!), this all &lt;em&gt;just works&lt;/em&gt;. And I have to hand it out here to the ASP.NET core guys. That&amp;rsquo;s pretty awesome. Back in the day, I had a harder time getting started with any JPA framework / configuration. But that might have been me as well.  Or the overwhelming amount of frameworks and choices. Oh well.&lt;/p&gt;

&lt;p&gt;Anyway, this all has no value unless it is delivered to production, right? So, how do ensure that there&amp;rsquo;s a SQL Server instance running in production? And that the TodoApi service can connect to it? Well, let&amp;rsquo;s keep it simple enough for now, and use docker-compose for that. Docker Compose is a tool that allows you to put container configuration (mind you, container, not image) in a &lt;code&gt;docker-compose.yml&lt;/code&gt; file. You can put in multiple containers, configure them, and then use something simple as &lt;code&gt;docker-compose up&lt;/code&gt; to ensure all containers are running.&lt;/p&gt;

&lt;p&gt;So, how does that look for our TodoApi?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yml&#34;&gt;version: &amp;quot;2&amp;quot;
services:
  mssql:
    image: microsoft/mssql-server-linux
    environment: 
      ACCEPT_EULA: &amp;quot;Y&amp;quot;
      SA_PASSWORD: &amp;quot;xihdG!8uNCavA!Rw&amp;quot;
    ports: 
      - 1433:1433
    networks:
      - production
  todo-api:
    image: corstijank/blog-dotnet-jenkins:2.0-59
    ports: 
      - 5000:5000
    networks: 
      - production
    depends_on: 
      - mssql
networks:
  production:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I like to think this is all pretty self-explanatory, but still, I&amp;rsquo;m going to give it a quick round-up:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;version: &amp;quot;2&amp;quot;&lt;/code&gt; - is just what version of the docker-compose syntax we&amp;rsquo;re using. I believe &amp;lsquo;3&amp;rsquo; or &amp;lsquo;3.1&amp;rsquo; is out, but haven&amp;rsquo;t gotten around to looking into that yet.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;services&lt;/code&gt; - Here are good bits; here declared are which services that need to be running according to this compose file. This translates into one, or more running containers

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mssql&lt;/code&gt; is our SQL Server service. It&amp;rsquo;s based on a docker image as you can see, has some environment variables (uh oh&amp;hellip;there&amp;rsquo;s my password again&amp;hellip;OR IS IT?), and describes what ports to publish. I&amp;rsquo;ll get to the networking in a bit&lt;/li&gt;
&lt;li&gt;&lt;code&gt;todo-api&lt;/code&gt; is the actual dotnet service. It publishes on port 5000, and depends on mssql. That at least ensure that the mssql is started first (sidenote: This does not necessarily mean todo-api gets started after SQL Server &lt;em&gt;has finished&lt;/em&gt; starting. There&amp;rsquo;s no check for that in here, for now)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;networks&lt;/code&gt; - I verbosely declare a &amp;lsquo;docker network&amp;rsquo; where the services are going to attach to. Amongst things, this ensures that services on the same network, can find each other by simple dns, using the other service&amp;rsquo;s name. So the hostname for SQL server service, from the todo-api container, is simply &lt;code&gt;mssql&lt;/code&gt; - as they are both on the same docker network.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, it gets interesting. Remember that dreaded &lt;code&gt;appsettings.json&lt;/code&gt;? The connection string clearly had SQL Server running on localhost. But if we run these containers, from the perspective of the todo-api container, SQL Server is not running on localhost, but rather on the hostname &lt;code&gt;mssql&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So, there is a  need for another JSON file. I called it &lt;code&gt;appsettings.docker.json&lt;/code&gt;. In this file, I switched out localhost for &lt;code&gt;mssql&lt;/code&gt;. I made sure to edit the &lt;code&gt;project.json&lt;/code&gt; file to include it when publishing the app, so it&amp;rsquo;ll get picked up into our container. Nice.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Now, I know pretty much all documentation and examples state to call it the JSON file something like &lt;code&gt;appsettings.production.json&lt;/code&gt; or for whichever environment it is. But, for building a docker container, I am against it those kind naming conventions. It implies something that might not be true. The settings file is going into the container. And the container does not know if it is running &lt;code&gt;production&lt;/code&gt; or &lt;code&gt;staging&lt;/code&gt; or whatever. So, I prefer to stick to a simple name that implies where the file is going; &lt;code&gt;appsettings.docker.json&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;final-steps&#34;&gt;Final steps&lt;/h2&gt;

&lt;p&gt;Finally, we need to make sure this is all executed in the pipeline when deploying to production. Tricky point here being the Todo-Api image name in the compose file. It points to a specific build number. So, when deploying, we need to:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Automatically edit the compose file and switch in the new image label&lt;/li&gt;
&lt;li&gt;Run docker compose&lt;/li&gt;
&lt;li&gt;Create a git commit for our edited compose file and push it&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That sounds complicated, but it&amp;rsquo;s actually not that bad:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;stage(&#39;Run in production&#39;){
    agent { label &#39;hasDocker&#39; }
    steps{
        dir(&#39;Environments/Production&#39;){
            sshagent([&#39;corstijank-ssh&#39;]){
                sh &amp;quot;&amp;quot;&amp;quot; sed -ie &#39;s#corstijank/blog-dotnet-jenkins:.*#${IMAGETAG_VERSIONED}#g&#39; docker-compose.yml
                    docker-compose up -d
                    git config user.email &amp;quot;jenkins@staticsmustdie.net&amp;quot;
                    git config user.name &amp;quot;Jenkins&amp;quot;
                    git checkout master
                    git commit -am &amp;quot;updated to ${IMAGETAG_VERSIONED}&amp;quot;
                    git push &amp;quot;&amp;quot;&amp;quot;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Probably the scariest part there is the &lt;code&gt;sed&lt;/code&gt; command. Yes, that is the UNIX Stream EDitor. If you&amp;rsquo;re on Mac OS or Linux, &amp;lsquo;man&amp;rsquo; it. It&amp;rsquo;s awesome. I&amp;rsquo;m sure there&amp;rsquo;s something equivalent on Windows that allows you to do that in a one-liner. Or rather, I hope. If not, there&amp;rsquo;s always BASH on Windows 10.&lt;/p&gt;

&lt;p&gt;So a quick explanation of the &lt;code&gt;sed&lt;/code&gt; line:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sed -ie &#39;s#corstijank/blog-dotnet-jenkins:.*#${IMAGETAG_VERSIONED}#g&#39; docker-compose.yml
         ^  ^                                ^                     ^           ^
        sub a string matching this regex     with this string   all matches    in this file
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The rest are basic git commands. I know, I could probably configure user email and name outside or globally. On the other hand, do I really want to depend on that? I don&amp;rsquo;t think this is too bad. Same goes for the &lt;code&gt;checkout master&lt;/code&gt; command. It just ensures we&amp;rsquo;re working on the master branch (or whichever branch you want to commit on). You could &lt;em&gt;assume&lt;/em&gt; you are in some state that might already be there, but why not &lt;strong&gt;make sure&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;Other side note: If you keep the compose file in the same git repository as the code, doing this might trigger another build if you&amp;rsquo;re using a git hook. Some simple alternative solutions to circumvent this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Use a smarter git hook that excludes pushes from Jenkins&lt;/li&gt;
&lt;li&gt;Push to  a separate branch that doesn&amp;rsquo;t start a build&lt;/li&gt;
&lt;li&gt;Push all infrastructure configuration to a separate git repository, separating infrastructure and business code.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;rsquo;m not going to state one is better then the other. Sorry, it&amp;rsquo;s just a choice. And one that could warrant a whole separate blog post.&lt;/p&gt;

&lt;p&gt;You could also do without the commit, but then you lose some pretty nice auditing.&lt;/p&gt;

&lt;p&gt;Finally, note I am using git over SSH. It&amp;rsquo;s just a bit easier to configure in Jenkins using the SSHAgent as in the example. There are workarounds when using http(s), but they basically all include substituting username and password in the url, which is just&amp;hellip;well&amp;hellip;I don&amp;rsquo;t like it.&lt;/p&gt;

&lt;h2 id=&#34;all-s-well-that-ends-well&#34;&gt;All&amp;rsquo;s well, that ends well&lt;/h2&gt;

&lt;p&gt;Well it&amp;rsquo;s been long run, but here we go:&lt;/p&gt;

&lt;asciinema-player src=&#34;http://staticsmustdie.net/asciinema/sqlserver.json&#34; cols=&#34;90&#34; rows=&#34;20&#34; preload=&#34;true&#34; poster=&#34;npt:0:07&#34;&gt;&lt;/asciinema-player&gt;


&lt;p&gt;And there you have it. A working delivery pipeline, including Microsoft&amp;rsquo;s own SQL server. Complete with database initialization, continuous delivery, you can even see in git log which version got deployed to production when.&lt;/p&gt;

&lt;p&gt;Also, you have managed to read through this ridiculously long blog post. It was too long in the making. Mostly due to circumstances such as vacation and the common cold, but also due to the fact that it&amp;rsquo;s not a small change to achieve. I could have split the topic up into two posts, but then I&amp;rsquo;d have to leave one blog post with a pipeline that either wasn&amp;rsquo;t working, or wasn&amp;rsquo;t representative for the way the code worked. Either was a no-no for me.&lt;/p&gt;

&lt;p&gt;But, I&amp;rsquo;m glad you stuck with me to the end ;-)&lt;/p&gt;

&lt;p&gt;Until the next time!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Crossing Styx - My journey into the (under)world of .NET - Part II</title>
      <link>http://staticsmustdie.net/post/dotnetcore-adventures-ii/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://staticsmustdie.net/post/dotnetcore-adventures-ii/</guid>
      <description>

&lt;p&gt;In my previous &lt;a href=&#34;http://staticsmustdie.net/post/dotnetcore-adventures-i/&#34;&gt;post on this topic&lt;/a&gt;, I somehow got the jitters to get started with .NET. Or more specifically, .NET core. Being stubborn as I am, I have created a simple delivery pipeline in Jenkins, for building and deploying a .NET core docker container.&lt;/p&gt;

&lt;p&gt;Now, this might sound like hell freezing over. Me, programming .NET? Blasphemy! Except one little thing. For my previous post, I didn&amp;rsquo;t actually write one line of C# code. Now, I don&amp;rsquo;t want to give off the impression Im uncomfortable in &lt;strong&gt;any&lt;/strong&gt; programming language, and so  I made sure to end the last blog post with some unfulfilled promises of creating a more serious project from this &amp;lsquo;Hello world&amp;rsquo; example.&lt;/p&gt;

&lt;p&gt;Time to pay up.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://staticsmustdie.net/img/dotnet-jenkins-simple-pipeline.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Previously..... on StaticsMustDie&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h2 id=&#34;the-freedom-of-choice&#34;&gt;The freedom of choice&lt;/h2&gt;

&lt;p&gt;So, I spent some time fiddling around, on how C# services work. To create any kind of web service, there is the ASP.NET core framework. ASP.NET core and the base .NET core runtime seem kind of coupled in a non-technical way. Of course, nowadays, you&amp;rsquo;d be hard pressed &lt;strong&gt;not&lt;/strong&gt; to write some sort of web application. And so far, to my knowledge, ASP.NET is the way to go for all the .NET folks.&lt;/p&gt;

&lt;p&gt;Still, the distinction between .NET core and ASP.NET core might allow for some possible alternatives in the future? Or, maybe not. It&amp;rsquo;s kind of like how, back in the day Java EE (back then still J2EE 1.2, 1.3) had the same kind of monopoly on the JVM when it came to developing back-end software (we didn&amp;rsquo;t do any of your fancy &amp;lsquo;web services&amp;rsquo; back then). At one point, Spring came along and provided a (more pragmatic, in this case) alternative. Competition grew, and now, Java developers have a bunch of choices to make on what they use. But, ultimately, the choice kind of boils down to some stylistic differences, about which people love to get all religious. Yay for choice, right?&lt;/p&gt;

&lt;p&gt;Anyway, I digress. Back to the matter at hand.&lt;/p&gt;

&lt;h2 id=&#34;to-code-or-not-to-code&#34;&gt;To Code, or not to Code&lt;/h2&gt;

&lt;p&gt;So, the choice for ASP.NET core was simple. Now, was I going to write a small service myself? I had originally planned too, but then, life got in the way. The whole household came down with the flu, and suddenly I was feeling kind of pressed for time. If I&amp;rsquo;m going to do this blog thing, I want to have at least some regularity to it, you know?&lt;/p&gt;

&lt;p&gt;The thing is, writing my own service&amp;hellip;was it really that important? I could follow a tutorial like anybody else. If I were to blog on that, I would just reproduce the tutorial, and that would not be up to the standards I want to hold myself to. I want to focus on the interesting points, Docker, Jenkins, unit testing, acceptance testing.&lt;/p&gt;

&lt;p&gt;So, instead of writing about how to implement REST on C#/.NET core, I&amp;rsquo;ll be starting with some simple tutorial code here. The ASP.NET core documentation site has some excellent &lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/tutorials/&#34; title=&#34;Awesome tutorials for learning ASP.NET core&#34;&gt;tutorials&lt;/a&gt;, and I really recommend you check them out. The code I&amp;rsquo;m starting with is the code explained the &lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/tutorials/&#34; title=&#34;Awesome tutorials for learning ASP.NET core&#34;&gt;ASP.NET core tutorial&lt;/a&gt; on creating a simple rest service.&lt;/p&gt;

&lt;h2 id=&#34;lessons-learned&#34;&gt;Lessons learned&lt;/h2&gt;

&lt;p&gt;So, I had refactor some stuff, &amp;lsquo;git mv&amp;rsquo; some directory around, and basically wound up with something which was starting to look like a real project folder;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/global.json
/TodoApi/Jenkinsfile
/TodoApi/Dockerfile
/TodoApi/project.json
/TodoApi/**Code**
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our Dockerfile is clean and simple; and I&amp;rsquo;m not going to bother going into detail on it here. All I had to do was edit the Jenkinsfile (read the previous post to get up to speed on that) to make sure any running version of the container would be stopped before the deploy. This was not necesary before as the previous iteration of our container was, well..just printing &lt;code&gt;hello world&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So, all should be well. Fire up the docker container. Query the service. Bask in .NET glory.&lt;/p&gt;

&lt;p&gt;Nope; ran into a few things that are well worth noting on here.&lt;/p&gt;

&lt;h3 id=&#34;inversion-of-control-just-on-a-different-level&#34;&gt;Inversion of Control. Just on a different level.&lt;/h3&gt;

&lt;p&gt;As I said, it was all relatively simple to start.  The container ran, but, when I tried to do a simple GET. It failed. Why? I got a simple &lt;code&gt;Empty Response&lt;/code&gt; as body text on my response. Why? Well there we have to look a bit deeper into the C# code, what it does, and how that holds up in our delivery choices.&lt;/p&gt;

&lt;p&gt;So, what does the code that start an http service look like?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;var host = new WebHostBuilder()
                .UseKestrel()
                .UseContentRoot(Directory.GetCurrentDirectory())
                .UseIISIntegration()
                .UseStartup&amp;lt;Startup&amp;gt;()
                .Build();
                
host.run();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My first thought seeing this was &amp;lsquo;Oh look, a simple builder that starts some kind of service. Nice. Just like we do it in Java in every (micro) service framework that is not JEE. They call it &amp;lsquo;Kestrel&amp;rsquo;? Well, that is a surprisingly non-utilitarian name for a Microsoft coined term. Shouldn&amp;rsquo;t it be called &amp;ldquo;InProcessIISAlternative&amp;rdquo;? Possibly with IIS spelled out?&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;/sarcasm&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So&amp;hellip;going on&amp;hellip;Use current directory as content root. Sure, integrate with IIS if you find it (tip: You won&amp;rsquo;t). Use an stance of &lt;code&gt;Startup&lt;/code&gt; as the startup object. All understandable. So why isn&amp;rsquo;t the bloody thing working?!&lt;/p&gt;

&lt;p&gt;Well, the problem is not in the code that&amp;rsquo;s there. The problem is in the code that &lt;strong&gt;is not&lt;/strong&gt; there. By default, a service started like this &lt;strong&gt;only&lt;/strong&gt; listens to &lt;code&gt;localhost:5000&lt;/code&gt;. That seems logical enough, right? It should work, right? Well yes, if you&amp;rsquo;re accessing form localhost.&lt;/p&gt;

&lt;p&gt;But, in our case, we are not. We are using Docker. Which means the service is running in a container. The container, from the perspective of our C# service, is &lt;code&gt;localhost&lt;/code&gt;. That means that anything accessing the container, almost by definition, will not be coming from &lt;code&gt;localhost&lt;/code&gt;, but rather as something more &lt;code&gt;remote&lt;/code&gt; from our application&amp;rsquo;s perspective.&lt;/p&gt;

&lt;p&gt;So, how to fix this? Well if you google around, you&amp;rsquo;re going to find a whole lot of information on configuration files you can edit. Maybe even for various stages like production or testing. I honestly didn&amp;rsquo;t really read into it that much. Not because I don&amp;rsquo;t care, but rather;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Application configuration files for network settings make no sense when you&amp;rsquo;re developing in containers. Whatever you configure in the configuration file, you can, and will override it when you deploy the container. For example, you could specify it with &lt;code&gt;-p&lt;/code&gt; or have Docker decide for you, or just ignore the port alltogether. Point is, the port that is going to be used to access your servie is not decided by your service. So don&amp;rsquo;t add another configuration file. Just hardcode it. You won&amp;rsquo;t be running any other services inside your container anyway, so port collisions are not an issue.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And hardcode I did;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;var host = new WebHostBuilder()
                .UseUrls(&amp;quot;http://0.0.0.0:5000/&amp;quot;)
         		.UseContentRoot(Directory.GetCurrentDirectory())
                .UseStartup&amp;lt;Startup&amp;gt;()
                .Build();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note I also deleted the IIS integration. I&amp;rsquo;ll have none of your shenanigans, IIS.&lt;/p&gt;

&lt;p&gt;After this, we end up with a runnable container;
&lt;asciinema-player src=&#34;http://staticsmustdie.net/asciinema/dotnet-jenkins-secondrun.json&#34; cols=&#34;90&#34; rows=&#34;20&#34; preload=&#34;true&#34; poster=&#34;npt:0:07&#34;&gt;&lt;/asciinema-player&gt;
&lt;/p&gt;

&lt;h3 id=&#34;crash-test-dummy&#34;&gt;Crash test dummy&lt;/h3&gt;

&lt;p&gt;So, I have a service running, a delivery pipeline  from the previous blog post, and actual value we can deliver to our shell using clients. At this point, even I am considering it might be smart to start adding some tests. The common practice for .NET projects seems to be to put the tests in a separate &amp;lsquo;project&amp;rsquo; if you will. So, create an empty directory, run &lt;code&gt;dotnet new -t xunittest&lt;/code&gt; and Bob&amp;rsquo;s your uncle.&lt;/p&gt;

&lt;p&gt;From here, it&amp;rsquo;s time implement the unit test. Again, not going to go into that much here. Suffice to say I managed to create something. If you&amp;rsquo;re interested on the unit test capabilities in (ASP).NET Core. There are some &lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/tutorials/&#34; title=&#34;Awesome tutorials for learning ASP.NET core&#34;&gt;really excellent tutorials here&lt;/a&gt; - what are you even doing still reading this?&lt;/p&gt;

&lt;p&gt;Oh right. The Jenkins pipeline. So, as you might know (if you read the tutorials!) the command to run tests is a simple &lt;code&gt;dotnet test&lt;/code&gt;. If you want to capture the results in a file, you should add some parameters to &lt;code&gt;dotnet&lt;/code&gt; call. Still, should be easy enough to integrate into our pipeline.&lt;/p&gt;

&lt;p&gt;Also, since these are unit tests, I want to make sure they are run before any building of docker images or whatsoever. Here&amp;rsquo;s the code in the &lt;code&gt;Jenkinsfile&lt;/code&gt; for the (renewed!) building stage:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt; stage(&#39;Build binaries&#39;){
  // Run this stage in a docker container with the dotnet sdk
  agent { docker &#39;microsoft/dotnet:latest&#39;}
  steps{
    git url: &#39;https://github.com/corstijank/blog-dotnet-jenkins.git&#39;
    sh &#39;cd TodoApi &amp;amp;&amp;amp; dotnet restore&#39;
    sh &#39;cd TodoApi.Test &amp;amp;&amp;amp; dotnet restore&#39;
    sh &#39;cd TodoApi.Test &amp;amp;&amp;amp; dotnet test -xml xunit-results.xml&#39;
    sh &#39;cd TodoApi &amp;amp;&amp;amp; dotnet publish project.json -c Release -r ubuntu.14.04-x64 -o ./publish&#39;
    stash includes: &#39;TodoApi/publish/**&#39;, name: &#39;prod_bins&#39; 
  }
  post{
    always{
      step([$class    : &#39;XUnitBuilder&#39;,
      thresholds: [[$class: &#39;FailedThreshold&#39;, failedThreshold: &#39;1&#39;]],
         tools     : [[$class: &#39;XUnitDotNetTestType&#39;, pattern: &#39;**/xunit-results.xml&#39;]]])
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are basically two things that are important here. First off, and most simple, is the &amp;lsquo;dotnet test&amp;rsquo; directive. We pipe the output to XML; which we are going to use in recording the results.&lt;/p&gt;

&lt;p&gt;In a &lt;code&gt;Jenkinsfile&lt;/code&gt;, each stage needs at least some &lt;code&gt;steps&lt;/code&gt;, obviously. But, we can also add a &lt;code&gt;post&lt;/code&gt; block. In this block, we can nest an &lt;code&gt;always&lt;/code&gt; block. Here, we can record our results using the XUnit plugin.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When you record test results in a &lt;code&gt;Jenkinsfile&lt;/code&gt;, be sure to always put the recording in something like a &lt;code&gt;post/always&lt;/code&gt; block, or if you&amp;rsquo;re using pure script, use a &lt;code&gt;try/finally&lt;/code&gt; construction. If your tests fail, the exit code will result in an exception. If you put the recording of your test results as a simple sequential step after the testing, it would mean execution would never reach the recording!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://staticsmustdie.net/img/dotnet-jenkins-tests-succesful.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;The serenity was not at a level I had hoped it to be&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://staticsmustdie.net/img/dotnet-jenkins-tests-failed.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Everything going as expected...&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;And&amp;hellip; that actually concludes integrating simple unit testing. It really was that easy.&lt;/p&gt;

&lt;p&gt;At first it might look like that amount of low-level &lt;code&gt;dotnet&lt;/code&gt; calls in our building stage might warrant some other, more abstract build tool to manage. But so far, I really don&amp;rsquo;t mind it. Having to, for example, fix the ordering between my source and test projects doesn&amp;rsquo;t seem like a big deal at all if you keep things small. For bigger things, well NuGet might help you with some dependency management there.&lt;/p&gt;

&lt;p&gt;There are &lt;strong&gt;probably&lt;/strong&gt; a whole bunch of cases where the &amp;lsquo;low-level&amp;rsquo; attitude of the &lt;code&gt;dotnet&lt;/code&gt; cli is going to fall short. I&amp;rsquo;m no experienced .NET developer. And I&amp;rsquo;m sure either Visual Studio or Team Foundation Server is going to offer some nice sugar on top, if they are not already. I don&amp;rsquo;t know.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m just using VSCode and Jenkins.&lt;/p&gt;

&lt;p&gt;And I don&amp;rsquo;t feel much need for anything else yet.&lt;/p&gt;

&lt;h2 id=&#34;wrap-up&#34;&gt;Wrap-up&lt;/h2&gt;

&lt;p&gt;So, that concludes the second part, in what looks like is going to be a three part adventure. The Jenkins pipeline we explored in the &lt;a href=&#34;http://staticsmustdie.net/post/dotnetcore-adventures-i/&#34;&gt;previous part&lt;/a&gt; was a fun introduction, but it was mostly dealing with Jenkins. This time around, we got into some interesting lessons on using ASP.NET Core with Docker, and what it would mean for configuration management.&lt;/p&gt;

&lt;p&gt;Also, it was very nice to see how relatively easy it is to integrate test results from the cli into Jenkins. I&amp;rsquo;ll admit that using the &lt;code&gt;step&lt;/code&gt; method is still a bit rough. I would rather use something like &lt;code&gt;xunit **/xunit-results.xml -t XUnitDotNetTest&lt;/code&gt; or something. But I&amp;rsquo;m sure the authors of the Jenkins plugin are going to get on that sometime.&lt;/p&gt;

&lt;p&gt;For the next post I plan on getting more creative; we have all the ground work laid out now. Let&amp;rsquo;s see what we can do with acceptance testing, docker-compose, and our Jenkins pipeline, to tear up and tear down a set of containers and some virtual networking as our acceptance testing environment. That&amp;rsquo;s when things start to look really interesting, I think.&lt;/p&gt;

&lt;p&gt;Again, if you&amp;rsquo;re curious about the full sources, or just want to peek at the complete picture, you can check out the &lt;a href=&#34;https://github.com/corstijank/blog-dotnet-jenkins&#34;&gt;repository at github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Crossing Styx - My journey into the (under)world of .NET - Part I</title>
      <link>http://staticsmustdie.net/post/dotnetcore-adventures-i/</link>
      <pubDate>Mon, 16 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>http://staticsmustdie.net/post/dotnetcore-adventures-i/</guid>
      <description>

&lt;p&gt;At the closing of last year, I presented an in-house talk, comparing Continuous Delivery solutions for both Java and .NET. Of course, this was not a simple side-by-side comparison; a microsoft oriented colleague and myself created a small challenge for ourselves. My colleague was going to build Java software in Team Foundation Server. And me? I was stuck creating a delivery pipeline for Microsoft .NET in Jenkins.&lt;/p&gt;

&lt;p&gt;Now, I had been thinking about looking into .NET since the appearance of &lt;strong&gt;.NET core&lt;/strong&gt;, and this gave me all the excuse I needed&amp;hellip;&lt;/p&gt;

&lt;p&gt;So, this is going to be the first in a series of blog posts journalling my adventures in .NET core. For this first post, Im going to be talking mostly on starting up a simple delivery pipeline using Jenkins. From this basic delivery pipeline, other posts in this series will focus on developing the developing the application, with unit tests, acceptance tests, all the while making sure our delivery pipeline stays up to date.&lt;/p&gt;

&lt;p&gt;Well then, let&amp;rsquo;s begin!&lt;/p&gt;

&lt;h2 id=&#34;hello-net-core&#34;&gt;Hello .NET core&lt;/h2&gt;

&lt;p&gt;So first off, we get started with a new .NET core application; using the .NET core runtime and the CLI tooling.&lt;/p&gt;

&lt;asciinema-player src=&#34;http://staticsmustdie.net/asciinema/dotnet-new-project.json&#34; cols=&#34;90&#34; rows=&#34;20&#34; preload=&#34;true&#34; poster=&#34;npt:0:07&#34;&gt;&lt;/asciinema-player&gt;


&lt;p&gt;Behold! The glory of &amp;ldquo;Hello World&amp;rdquo; in .NET Core. So, a couple of interesting things to note:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dotnet new&lt;/code&gt; creates a simple, new C# project. Luckily, no VB.NET shenanigans. This basically creates a &lt;code&gt;Program.cs&lt;/code&gt; file and a &lt;code&gt;project.json&lt;/code&gt; file. The JSON file is kind of like your Maven pom file or your Gradle build file. Kind of.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dotnet restore&lt;/code&gt; downloads all dependencies into the local cache, so you&amp;rsquo;re good to go. Interesting fact; you always need to run &lt;code&gt;dotnet restore&lt;/code&gt; separately, it is not included as a part of something like &lt;code&gt;dotnet run&lt;/code&gt; or &lt;code&gt;dotnet publish&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dotnet run&lt;/code&gt; does two things. Our program is not yet compiled, so it implicitly does a build of our program (&lt;code&gt;dotnet build&lt;/code&gt;). Then, it runs the program, resulting in our much desired &amp;lsquo;Hello World&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For now, this is about all I need. I have a &amp;lsquo;Hello World&amp;rsquo; program, I can clone it anywhere, and get it building and running.&lt;/p&gt;

&lt;p&gt;So, coolest thing about this all? It&amp;rsquo;s all native on my Mac. And want to know what&amp;rsquo;s even better? It works just as well on Linux. And just like that, running and distributing our application got a whole lot easier, as I, for one, hail our Docker overlords.&lt;/p&gt;

&lt;h2 id=&#34;on-jenkins-2&#34;&gt;On Jenkins 2&lt;/h2&gt;

&lt;p&gt;Now, as I said, I had extra motivation for my experiments to use Jenkins as a build tool. One, it was the topic of the talk. And of course two, it&amp;rsquo;s just better then TFS or VSTS &lt;em&gt;coughs&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Ok, well, let&amp;rsquo;s not go into that comparison on here.&lt;/p&gt;

&lt;p&gt;At the very least, Jenkins&amp;rsquo; delivery pipelines are fun to experiment with, and allow us to create a delivery pipeline, as code (as opposed to clicking through a bunch of screens). Last year, while Microsoft was busy developing dotnet core, Cloudbees (the company mostly behind Jenkins) has been busy developing Jenkins 2, and focussing on delivery pipelines.&lt;/p&gt;

&lt;p&gt;Though still in development, the delivery pipeline vision from Jenkins has been clear throughout; All build configuration is scripted, in a file called &lt;code&gt;Jenkinsfile&lt;/code&gt; that you keep in git with your software.&lt;/p&gt;

&lt;p&gt;There are, at this moment, two &amp;lsquo;flavors&amp;rsquo; of Jenkinsfile;
-  a pure groovy script. Allows for maximal freedom, but is error prone, and often not as readable
- a declarative script. Syntax is more defined; less chance for errors at the cost of flexibility. Also, the syntax is not quite final yet (beta2 at this moment of writing)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If your &lt;code&gt;Jenkinsfile&lt;/code&gt; starts with something akin to &lt;code&gt;node{&lt;/code&gt; you&amp;rsquo;re looking at a script that allows all kinds of groovy code. You can do anything, but it&amp;rsquo;s easy to make mistakes. If the file starts with &lt;code&gt;pipeline{&lt;/code&gt; the syntax is much more strictly defined, but more readable. I would advice to use the declarative &lt;code&gt;pipeline{&lt;/code&gt; style for new projects.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For this project, we&amp;rsquo;re going to use the declarative style. In my opinion, it&amp;rsquo;s cleaner, and it certainly looks like it&amp;rsquo;s the direction Cloudbees is heading towards.&lt;/p&gt;

&lt;h2 id=&#34;back-to-the-core-of-things&#34;&gt;Back to the core of things.&lt;/h2&gt;

&lt;p&gt;Now, that&amp;rsquo;s all nice and well, but what about our awesome hello world application? Well, let&amp;rsquo;s get started on a delivery pipeline for that. What&amp;rsquo;s going to be delivery architecture? Our application is going to be packaged into a docker container, and uploaded to docker hub. From there, deployment to production should be easy enough. Let&amp;rsquo;s begin.&lt;/p&gt;

&lt;h3 id=&#34;building-the-code&#34;&gt;Building the code&lt;/h3&gt;

&lt;p&gt;So, I created a first stage called &amp;lsquo;Build Binaries&amp;rsquo; to begin with. It builds our .NET core binaries.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;stage(&#39;Build binaries&#39;){
  agent { docker &#39;microsoft/dotnet:latest&#39;}
  steps{
    git url: &#39;https://github.com/corstijank/blog-dotnet-jenkins.git&#39;
    sh &#39;dotnet restore&#39;
    sh &#39;dotnet publish project.json -c Release -r ubuntu.14.04-x64 -o ./publish&#39;
    stash includes: &#39;publish/**&#39;, name: &#39;prod_bins&#39; 
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s start with the line where declare which agent we are going to use for this stage. We use a docker container as our agent, and base it on the &lt;code&gt;microsoft/dotnet:latest&lt;/code&gt; image. This is a simple line, but this has some pretty neat implications. It basically means, for this pipeline to run, we don&amp;rsquo;t need to install the .NET core SDK anywhere. All we need is access to a docker host. The pipeline downloads the image, starts a container, and executes the steps of our stage &lt;em&gt;inside&lt;/em&gt; the container.&lt;/p&gt;

&lt;p&gt;Need to pin a specific version? No problem. Just use a different docker tag. Want to build on a new version of the SDK? Use a different docker tag. Never install a .NET SDK on a build server again. It&amp;rsquo;s &lt;strong&gt;glorious&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So, what do we run our container? Basically three things; we clone the git repository, restore the dependencies, and publish our application. This is all pretty basic .NET core CLI stuff.&lt;/p&gt;

&lt;p&gt;Lastly, and this is important, we use &lt;code&gt;stash&lt;/code&gt; to copy the resulting binaries &lt;strong&gt;out&lt;/strong&gt; of our container. This basically creates a zip file of everything in the specified directory, and ensures that zipfile is made available on request to later stages in the pipeline under the specified name.&lt;/p&gt;

&lt;h3 id=&#34;3-2-1-dockerize&#34;&gt;3&amp;hellip;2&amp;hellip;1&amp;hellip;Dockerize!&lt;/h3&gt;

&lt;p&gt;Now that we have our binaries, it&amp;rsquo;s time to create our docker image. I purposefully put this as a separate stage.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Simply said, the requirements for the &lt;strong&gt;steps&lt;/strong&gt; in this stage, being, access to a Docker daemon, are different than the requirements for the &lt;strong&gt;steps&lt;/strong&gt;of the previous stage (access to the .NET core sdk). Much like object oriented programming, this is a pretty good pointer to decouple stages in the delivery pipeline.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s look at the pipeline:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;stage(&#39;Create docker image&#39;){
    agent { label &#39;hasDocker&#39; }
    environment {
        DOCKER_ID = credentials(&#39;docker-id&#39;)
    }
    steps{
        // Unstash the binaries from the previous tage
        unstash &#39;prod_bins&#39;
        sh &amp;quot;&amp;quot;&amp;quot;  docker build -t corstijank/blog-dotnet-jenkins:1.0-${env.BUILD_NUMBER} .
                docker tag corstijank/blog-dotnet-jenkins:1.0-${env.BUILD_NUMBER} corstijank/blog-dotnet-jenkins:latest
                docker login -u ${DOCKER_ID_USR} -p ${DOCKER_ID_PSW}
                docker push corstijank/blog-dotnet-jenkins:1.0-${env.BUILD_NUMBER}
                docker push corstijank/blog-dotnet-jenkins:latest &amp;quot;&amp;quot;&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There&amp;rsquo;s a bunch of new stuff going on here. Let&amp;rsquo;s inspect. We run this stage on any Jenkins agent that has a label called &amp;lsquo;hasDocker&amp;rsquo;. The label is just something I made up; but it&amp;rsquo;s a nice way of identify if a Jenkins agent comes with access to a Docker daemon or not. Mind you, this stage does not run &lt;strong&gt;in&lt;/strong&gt; in a docker container. It&amp;rsquo;s just a simple process on the agent executing it.&lt;/p&gt;

&lt;p&gt;Also, we ask Jenkins for credentials, under the ID &amp;lsquo;docker-id&amp;rsquo;. Again, this is an identifier I made up myself. It&amp;rsquo;s up the Jenkins administrator to create some credentials to a DockerHub id in the Jenkins instance.&lt;/p&gt;

&lt;p&gt;From there on, it&amp;rsquo;s pretty self-explanatory. We unstash (read: unzip) the created binaries. We use docker build to create an image based on a &lt;code&gt;Dockerfile&lt;/code&gt; in our repository. We tag it using both the build number, and a latest tag. We log in to DockerHub with our credentials, and we push our images.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the Dockerfile;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Dockerfile&#34;&gt;FROM microsoft/dotnet:runtime
COPY publish /app
WORKDIR /app
RUN [&amp;quot;chmod&amp;quot;, &amp;quot;744&amp;quot;, &amp;quot;./blog-dotnet-jenkins&amp;quot;] 
ENTRYPOINT [&amp;quot;./blog-dotnet-jenkins&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use the .NET core runtime here; as we don&amp;rsquo;t need the full SDK. We add our &lt;code&gt;publish&lt;/code&gt; folder as &lt;code&gt;/app&lt;/code&gt;, and mark the executable file as such. The &lt;code&gt;ENTRYPOINT&lt;/code&gt; points to the executable file, ensuring its execution when starting the container.&lt;/p&gt;

&lt;p&gt;If we run this pipeline in our Jenkins instance, we have achieved, a fully runnable docker image!&lt;/p&gt;

&lt;p&gt;Success!&lt;/p&gt;

&lt;asciinema-player src=&#34;http://staticsmustdie.net/asciinema/dotnet-jenkins-firstrun.json&#34; cols=&#34;90&#34; rows=&#34;10&#34; preload=&#34;true&#34; poster=&#34;npt:0:07&#34;&gt;&lt;/asciinema-player&gt;


&lt;h3 id=&#34;f-ck-it-ship-it&#34;&gt;F*ck it, ship it&lt;/h3&gt;

&lt;p&gt;The final stage really isn&amp;rsquo;t anything special for now:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;stage(&#39;Run in production&#39;){
  agent { label &#39;hasDocker&#39; }
  steps{
    sh &amp;quot;docker run -d corstijank/blog-dotnet-jenkins:1.0-${env.BUILD_NUMBER}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, this is not anywhere near a satisfying production environment. I promise to extend our pipeline to make sure we deploy nicely to separate docker host representing our production server. Or maybe some container service somewhere. At this point, it&amp;rsquo;s all Docker anyway, and that should be the least of my struggles in the coming adventure.&lt;/p&gt;

&lt;h2 id=&#34;deliver-first-develop-later&#34;&gt;Deliver first, develop later&lt;/h2&gt;

&lt;p&gt;So, maybe I went a bit overboard for a simple &lt;code&gt;Hello World&lt;/code&gt; application. I think many developers tend to focus too much first on developing features, instead of delivering features. The whole idea was to test if a .NET core application could be delivered using Jenkins. Never mind the feature yet. For now, it&amp;rsquo;s looking rather glorious. Of course there are going to be add ons and challenges later;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;unit testing&lt;/li&gt;
&lt;li&gt;acceptance testing with some kind of database backend&lt;/li&gt;
&lt;li&gt;actual deployment to an actual production environment&lt;/li&gt;
&lt;li&gt;gathering test and deployment results&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But honestly, after this experiment I feel confident about using .NET core on Jenkins. And it almost pains me to say it, but Im kind of looking forward into experiment and building this little project. So, definitely to be continued soon.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re curious about the full sources, or just want to peek at the complete picture, you can check out the &lt;a href=&#34;https://github.com/corstijank/blog-dotnet-jenkins&#34;&gt;repository at github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Any questions? Feel free to shoot away below!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>